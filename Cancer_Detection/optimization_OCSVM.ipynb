{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pyod.models.iforest import IForest\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "import os\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from pyod.models.pca import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import os, sys, pickle\n",
    "import argparse, sys\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('-label', help=' : Please set the label') \n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/modified_dataset.csv')\n",
    "\n",
    "\n",
    "# def remove_outliers(df, column_name, factor=1.5):\n",
    "#     Q1 = df[column_name].quantile(0.25)\n",
    "#     Q3 = df[column_name].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - factor * IQR\n",
    "#     upper_bound = Q3 + factor * IQR\n",
    "#     df_filtered = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "#     return df_filtered\n",
    "\n",
    "# # 모든 칼럼에 대해 이상치 제거 실행\n",
    "# for column_name in df.columns:\n",
    "#     df = remove_outliers(df, column_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_stroke_0 = df[df['Cancer'] == 0]\n",
    "df_stroke_1 = df[df['Cancer'] == 1]\n",
    "\n",
    "\n",
    "\n",
    "#train, test data processing 1,2,3,4중 선택\n",
    "\n",
    "#1.정상으로만 학습, 테스트는 정상과 이상 반반\n",
    "answer_label = 'Cancer'\n",
    "X = df[df.columns.difference([answer_label])]\n",
    "df_normal = df[df[answer_label] == 0]\n",
    "df_abnormal = df[df[answer_label] == 1]\n",
    "test_normal_df = df_normal.sample(n=len(df_stroke_1), random_state = 0)\n",
    "test_df = pd.concat([df_abnormal, test_normal_df])\n",
    "X_test = test_df[test_df.columns.difference([answer_label])]\n",
    "y_test = test_df[answer_label]\n",
    "train_df = df_normal.drop(test_normal_df.index)\n",
    "X_train = train_df[train_df.columns.difference([answer_label])]\n",
    "y_train = train_df[answer_label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "def main_task(kernel, nu):\n",
    "    ocsvm = OneClassSVM(kernel=kernel, nu = nu, verbose = True)\n",
    "    ocsvm.fit(X_train)\n",
    "    ocsvm_test_pred = ocsvm.predict(X_test)\n",
    "    ocsvm_test_pred = pd.DataFrame(ocsvm_test_pred)\n",
    "    ocsvm_test_pred = ocsvm_test_pred.replace({-1:1, 1:0})\n",
    "    return round(f1_score(y_test, ocsvm_test_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:43:33,967] A new study created in memory with name: no-name-9b3ee10e-11ec-4ea0-bc74-41cb58bc73d8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel :  poly\n",
      "nu :  0.25\n",
      "[LibSVM]..\n",
      "Warning: using -h 0 may be faster\n",
      "*.\n",
      "Warning: using -h 0 may be faster\n",
      "*.\n",
      "Warning: using -h 0 may be faster\n",
      "*"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:43:36,326] Trial 0 finished with value: 0.031 and parameters: {'kernel': 'poly', 'nu': 0.25}. Best is trial 0 with value: 0.031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 3325\n",
      "obj = 762.923815, rho = 1.243314\n",
      "nSV = 2674, nBSV = 2657\n",
      "<f1_score: 0.031 >\n",
      "kernel :  poly\n",
      "nu :  0.75\n",
      "[LibSVM]..\n",
      "Warning: using -h 0 may be faster\n",
      "*.\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 2506\n",
      "obj = 173590.939973, rho = 106.852912\n",
      "nSV = 8003, nBSV = 7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:43:39,299] Trial 1 finished with value: 0.259 and parameters: {'kernel': 'poly', 'nu': 0.75}. Best is trial 1 with value: 0.259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<f1_score: 0.259 >\n",
      "kernel :  linear\n",
      "nu :  0.75\n",
      "[LibSVM]*...............................................................\n",
      "Warning: using -h 0 may be faster\n",
      "*.......................................................................................\n",
      "Warning: using -h 0 may be faster\n",
      "*.....\n",
      "Warning: using -h 0 may be faster\n",
      "*.....\n",
      "Warning: using -h 0 may be faster\n",
      "*........\n",
      "Warning: using -h 0 may be faster\n",
      "*..\n",
      "Warning: using -h 0 may be faster\n",
      "*.......\n",
      "Warning: using -h 0 may be faster\n",
      "*..\n",
      "Warning: using -h 0 may be faster\n",
      "*..........\n",
      "Warning: using -h 0 may be faster\n",
      "*.........\n",
      "Warning: using -h 0 may be faster\n",
      "*..\n",
      "Warning: using -h 0 may be faster\n",
      "*...\n",
      "Warning: using -h 0 may be faster\n",
      "*.....\n",
      "Warning: using -h 0 may be faster\n",
      "*...........................\n",
      "Warning: using -h 0 may be faster\n",
      "*......\n",
      "Warning: using -h 0 may be faster\n",
      "*..........\n",
      "Warning: using -h 0 may be faster\n",
      "*.........\n",
      "Warning: using -h 0 may be faster\n",
      "*............................\n",
      "Warning: using -h 0 may be faster\n",
      "*..\n",
      "Warning: using -h 0 may be faster\n",
      "*.....\n",
      "Warning: using -h 0 may be faster\n",
      "*....\n",
      "Warning: using -h 0 may be faster\n",
      "*............\n",
      "Warning: using -h 0 may be faster\n",
      "*.\n",
      "Warning: using -h 0 may be faster\n",
      "*.......\n",
      "Warning: using -h 0 may be faster\n",
      "*.....\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 303570\n",
      "obj = -0.291882, rho = -0.000087\n",
      "nSV = 8143, nBSV = 7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:43:59,529] Trial 2 finished with value: 0.483 and parameters: {'kernel': 'linear', 'nu': 0.75}. Best is trial 2 with value: 0.483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<f1_score: 0.483 >\n",
      "kernel :  poly\n",
      "nu :  0.6900000000000001\n",
      "[LibSVM]..\n",
      "Warning: using -h 0 may be faster\n",
      "*"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:02,113] Trial 3 finished with value: 0.238 and parameters: {'kernel': 'poly', 'nu': 0.6900000000000001}. Best is trial 2 with value: 0.483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 3069\n",
      "obj = 114057.589800, rho = 79.689794\n",
      "nSV = 7362, nBSV = 7352\n",
      "<f1_score: 0.238 >\n",
      "kernel :  poly\n",
      "nu :  0.99\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:03,789] Trial 4 finished with value: 0.614 and parameters: {'kernel': 'poly', 'nu': 0.99}. Best is trial 4 with value: 0.614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "optimization finished, #iter = 194\n",
      "obj = 9620971.852135, rho = 54176.539559\n",
      "nSV = 10557, nBSV = 10556\n",
      "<f1_score: 0.614 >\n",
      "kernel :  linear\n",
      "nu :  0.53\n",
      "[LibSVM]*....................................................\n",
      "Warning: using -h 0 may be faster\n",
      "*...........\n",
      "Warning: using -h 0 may be faster\n",
      "*...................................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:12,139] Trial 5 finished with value: 0.784 and parameters: {'kernel': 'linear', 'nu': 0.53}. Best is trial 5 with value: 0.784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 178987\n",
      "obj = -0.142541, rho = -0.000080\n",
      "nSV = 5757, nBSV = 5432\n",
      "<f1_score: 0.784 >\n",
      "kernel :  sigmoid\n",
      "nu :  0.63\n",
      "[LibSVM]..\n",
      "Warning: using -h 0 may be faster\n",
      "*"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:17,301] Trial 6 finished with value: 0.785 and parameters: {'kernel': 'sigmoid', 'nu': 0.63}. Best is trial 6 with value: 0.785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 2473\n",
      "obj = -682617.099969, rho = -45.527624\n",
      "nSV = 6721, nBSV = 6715\n",
      "<f1_score: 0.785 >\n",
      "kernel :  linear\n",
      "nu :  0.53\n",
      "[LibSVM]*....................................................\n",
      "Warning: using -h 0 may be faster\n",
      "*...........\n",
      "Warning: using -h 0 may be faster\n",
      "*.....................................................................................................................\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 178987\n",
      "obj = -0.142541, rho = -0.000080\n",
      "nSV = 5757, nBSV = 5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:26,572] Trial 7 finished with value: 0.784 and parameters: {'kernel': 'linear', 'nu': 0.53}. Best is trial 6 with value: 0.785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<f1_score: 0.784 >\n",
      "kernel :  linear\n",
      "nu :  0.6900000000000001\n",
      "[LibSVM]*...........................................................................................................................................................................\n",
      "Warning: using -h 0 may be faster\n",
      "*.........\n",
      "Warning: using -h 0 may be faster\n",
      "*...................\n",
      "Warning: using -h 0 may be faster\n",
      "*...\n",
      "Warning: using -h 0 may be faster\n",
      "*."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:37,731] Trial 8 finished with value: 0.759 and parameters: {'kernel': 'linear', 'nu': 0.6900000000000001}. Best is trial 6 with value: 0.785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 201806\n",
      "obj = -0.240414, rho = -0.000089\n",
      "nSV = 7476, nBSV = 7092\n",
      "<f1_score: 0.759 >\n",
      "kernel :  linear\n",
      "nu :  0.21000000000000002\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:38,105] Trial 9 finished with value: 0.147 and parameters: {'kernel': 'linear', 'nu': 0.21000000000000002}. Best is trial 6 with value: 0.785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "optimization finished, #iter = 415\n",
      "obj = -0.020019, rho = 0.000085\n",
      "nSV = 2259, nBSV = 2212\n",
      "<f1_score: 0.147 >\n",
      "kernel :  sigmoid\n",
      "nu :  0.35000000000000003\n",
      "[LibSVM]."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:41,607] Trial 10 finished with value: 0.8 and parameters: {'kernel': 'sigmoid', 'nu': 0.35000000000000003}. Best is trial 10 with value: 0.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 2080\n",
      "obj = -451529.794452, rho = -113.941063\n",
      "nSV = 3733, nBSV = 3729\n",
      "<f1_score: 0.8 >\n",
      "kernel :  sigmoid\n",
      "nu :  0.37\n",
      "[LibSVM]..\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 2303\n",
      "obj = -475259.035423, rho = -108.534407\n",
      "nSV = 3948, nBSV = 3942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:45,215] Trial 11 finished with value: 0.792 and parameters: {'kernel': 'sigmoid', 'nu': 0.37}. Best is trial 10 with value: 0.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<f1_score: 0.792 >\n",
      "kernel :  sigmoid\n",
      "nu :  0.05\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 14:44:45,681] Trial 12 finished with value: 0.428 and parameters: {'kernel': 'sigmoid', 'nu': 0.05}. Best is trial 10 with value: 0.8.\n",
      "[W 2023-11-08 14:44:45,691] Trial 13 failed with parameters: {'kernel': 'precomputed', 'nu': 0.35000000000000003} because of the following error: ValueError('Precomputed matrix must be a square matrix. Input is a 10663x5 matrix.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohee/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_11715/3985630578.py\", line 11, in optuna_main\n",
      "    f1_score = main_task(kernel = kernel, nu = nu)\n",
      "  File \"/tmp/ipykernel_11715/3548912541.py\", line 4, in main_task\n",
      "    ocsvm.fit(X_train)\n",
      "  File \"/home/mohee/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 1814, in fit\n",
      "    super().fit(X, np.ones(_num_samples(X)), sample_weight=sample_weight)\n",
      "  File \"/home/mohee/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mohee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 215, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Precomputed matrix must be a square matrix. Input is a 10663x5 matrix.\n",
      "[W 2023-11-08 14:44:45,694] Trial 13 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "optimization finished, #iter = 431\n",
      "obj = -31762.924855, rho = -94.067111\n",
      "nSV = 534, nBSV = 532\n",
      "<f1_score: 0.428 >\n",
      "kernel :  precomputed\n",
      "nu :  0.35000000000000003\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Precomputed matrix must be a square matrix. Input is a 10663x5 matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m f1_score\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(optuna_main, n_trials\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstudy.best_trial.value : \u001b[39m\u001b[39m{\u001b[39;00mstudy\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstudy.best_params : \u001b[39m\u001b[39m{\u001b[39;00mstudy\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkernel : \u001b[39m\u001b[39m'\u001b[39m, kernel)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnu : \u001b[39m\u001b[39m'\u001b[39m, nu)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m f1_score \u001b[39m=\u001b[39m main_task(kernel \u001b[39m=\u001b[39;49m kernel, nu \u001b[39m=\u001b[39;49m nu)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m<f1_score:\u001b[39m\u001b[39m'\u001b[39m, f1_score,\u001b[39m'\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f1_score\n",
      "\u001b[1;32m/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain_task\u001b[39m(kernel, nu):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     ocsvm \u001b[39m=\u001b[39m OneClassSVM(kernel\u001b[39m=\u001b[39mkernel, nu \u001b[39m=\u001b[39m nu, verbose \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     ocsvm\u001b[39m.\u001b[39;49mfit(X_train)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     ocsvm_test_pred \u001b[39m=\u001b[39m ocsvm\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mohee/work/Anomaly-Detection/Cancer_Detection/optimization_OCSVM.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     ocsvm_test_pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(ocsvm_test_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:1814\u001b[0m, in \u001b[0;36mOneClassSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1790\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Detect the soft boundary of the set of samples X.\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m \n\u001b[1;32m   1792\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[39m    If X is not a C-ordered contiguous array it is copied.\u001b[39;00m\n\u001b[1;32m   1813\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1814\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, np\u001b[39m.\u001b[39;49mones(_num_samples(X)), sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m   1815\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset_ \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intercept_\n\u001b[1;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:215\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    210\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mX and y have incompatible shapes.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m samples, but y has \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_samples, y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    212\u001b[0m     )\n\u001b[1;32m    214\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m n_samples \u001b[39m!=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    216\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPrecomputed matrix must be a square matrix.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Input is a \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39mx\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m matrix.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m sample_weight\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m sample_weight\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m n_samples:\n\u001b[1;32m    221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msample_weight and X have incompatible shapes: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[39m%\u001b[39m (sample_weight\u001b[39m.\u001b[39mshape, X\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    227\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Precomputed matrix must be a square matrix. Input is a 10663x5 matrix."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def optuna_main(trial: optuna.Trial):\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'])\n",
    "    nu = trial.suggest_float('nu', 0.01, 1.00, step = 0.02)\n",
    "    print('kernel : ', kernel)\n",
    "    print('nu : ', nu)\n",
    "\n",
    "    f1_score = main_task(kernel = kernel, nu = nu)\n",
    "\n",
    "    print('<f1_score:', f1_score,'>')\n",
    "    return f1_score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optuna_main, n_trials=300)\n",
    "print(f'study.best_trial.value : {study.best_trial.value}')\n",
    "print(f'study.best_params : {study.best_trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study.best_trial.value : 0.801\n",
      "study.best_paramse : {'contamination': 0.15000000000000002, 'n_bins': 10}\n"
     ]
    }
   ],
   "source": [
    "#결과\n",
    "print(f'study.best_trial.value : {study.best_trial.value}')\n",
    "print(f'study.best_paramse : {study.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
